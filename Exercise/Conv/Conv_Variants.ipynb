{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1 align=center><font size = 5>Convolution Variants</h1 >",
   "id": "9ca22c3fe0c5fa16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>Objective for this Notebook</h3>\n",
    "<h5> 1. 了解不同的卷積變體，在程式如何使用</h5>"
   ],
   "id": "80799a210c7ea1ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Table of Contents\n",
    "<li><a href=\"#ref0\">標準卷積（Standard Convolution）</a></li>\n",
    "<li><a href=\"#ref1\">1x1卷積（1x1 Convolution）</a></li>\n",
    "<li><a href=\"#ref2\">動態卷積（Dynamic Convolution）</a></li>\n",
    "<li><a href=\"#ref3\">轉置卷積（Transposed Convolution）</a></li>\n",
    "<li><a href=\"#ref4\">膨脹卷積（Dilated Convolution）</a></li>\n",
    "<li><a href=\"#ref5\">空間可分離卷積（Spatially Separable Convolution）</a></li>\n",
    "<li><a href=\"#ref6\">深度可分離卷積（Depthwise Separable Convolution）</a></li>\n",
    "<li><a href=\"#ref7\">展平卷積（Flattened Convolution）</a></li>\n",
    "<li><a href=\"#ref8\">分組卷積（Grouped Convolution）</a></li>\n",
    "<li><a href=\"#ref9\">混洗分組卷積（Shuffled Grouped Convolution）</a></li>\n",
    "<hr>"
   ],
   "id": "f4aaf1ab6c974eb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref0\"></a>\n",
    "<h1 align=center><font size = 5>標準卷積（Standard Convolution）</h1 >"
   ],
   "id": "81650de8bb8a161b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:55.445460Z",
     "start_time": "2025-03-17T08:00:55.442948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StandardConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "e0ad178682815e7f",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:55.476221Z",
     "start_time": "2025-03-17T08:00:55.469202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "std_conv = StandardConv(3, 64, 3)\n",
    "output_std = std_conv(input_tensor)\n",
    "print(\"StandardConv output shape:\", output_std.shape)  # 預期輸出: torch.Size([1, 64, 222, 222])"
   ],
   "id": "5a485c747c47b61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardConv output shape: torch.Size([1, 64, 222, 222])\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h1 align=center><font size = 5>1x1卷積（1x1 Convolution）</h1 >"
   ],
   "id": "98256f64922551f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:55.506611Z",
     "start_time": "2025-03-17T08:00:55.503327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OneByOneConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "3971abea52b62cd1",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:55.535114Z",
     "start_time": "2025-03-17T08:00:55.529094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "one_by_one_conv = OneByOneConv(3, 64)\n",
    "output_1x1 = one_by_one_conv(input_tensor)\n",
    "print(\"OneByOneConv output shape:\", output_1x1.shape)  # 預期輸出: torch.Size([1, 64, 224, 224])"
   ],
   "id": "2ab0e597b33813a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneByOneConv output shape: torch.Size([1, 64, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h1 align=center><font size = 5>動態卷積（Dynamic Convolution）</h1 >"
   ],
   "id": "10f05a6d17765c9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:55.542004Z",
     "start_time": "2025-03-17T08:00:55.538619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DynamicConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * in_channels * kernel_size * kernel_size, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, h, w = x.size()\n",
    "        kernel = self.conv(x)\n",
    "        kernel = kernel.view(batch_size, self.out_channels, self.in_channels * self.kernel_size * self.kernel_size, h, w)\n",
    "        x_unfolded = torch.nn.functional.unfold(x, self.kernel_size, padding=(self.kernel_size-1)//2)\n",
    "        x_unfolded = x_unfolded.view(batch_size, self.in_channels * self.kernel_size * self.kernel_size, h * w)\n",
    "        kernel = kernel.view(batch_size, self.out_channels, self.in_channels * self.kernel_size * self.kernel_size, h * w)\n",
    "        output = torch.einsum('boip,bip->bop', kernel, x_unfolded)\n",
    "        output = output.view(batch_size, self.out_channels, h, w)\n",
    "        return output"
   ],
   "id": "23a1131ac382246b",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.186030Z",
     "start_time": "2025-03-17T08:00:55.562384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dynamic_conv = DynamicConv(3, 64, 3)\n",
    "output_dynamic = dynamic_conv(input_tensor)\n",
    "print(\"DynamicConv output shape:\", output_dynamic.shape)  # 預期輸出: torch.Size([1, 64, 224, 224])"
   ],
   "id": "4186cced10e15b70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicConv output shape: torch.Size([1, 64, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref3\"></a>\n",
    "<h1 align=center><font size = 5>轉置卷積（Transposed Convolution）</h1 >"
   ],
   "id": "342233e050bad707"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.209009Z",
     "start_time": "2025-03-17T08:00:56.206599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransposedConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "a8af9bc50535d836",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.244389Z",
     "start_time": "2025-03-17T08:00:56.230056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transposed_conv = TransposedConv(3, 64, 2, stride=2)\n",
    "output_transposed = transposed_conv(input_tensor)\n",
    "print(\"TransposedConv output shape:\", output_transposed.shape)  # 預期輸出: torch.Size([1, 64, 448, 448])"
   ],
   "id": "86f1bf39aae9833e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransposedConv output shape: torch.Size([1, 64, 448, 448])\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref4\"></a>\n",
    "<h1 align=center><font size = 5>膨脹卷積（Dilated Convolution）</h1 >"
   ],
   "id": "3ca698d2b492f3ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.268181Z",
     "start_time": "2025-03-17T08:00:56.265163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DilatedConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "b6982b4dc6998d90",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.327577Z",
     "start_time": "2025-03-17T08:00:56.289165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dilated_conv = DilatedConv(3, 64, 3, dilation=2)\n",
    "output_dilated = dilated_conv(input_tensor)\n",
    "print(\"DilatedConv output shape:\", output_dilated.shape)  # 預期輸出: torch.Size([1, 64, 220, 220])"
   ],
   "id": "f1bb78cde23eeb13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DilatedConv output shape: torch.Size([1, 64, 220, 220])\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref5\"></a>\n",
    "<h1 align=center><font size = 5>空間可分離卷積（Spatially Separable Convolution）</h1 >"
   ],
   "id": "ebba9b34508a7b3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.351130Z",
     "start_time": "2025-03-17T08:00:56.347124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SpatiallySeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_h = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.conv_w = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_h = self.conv_h(x)\n",
    "        x_w = self.conv_w(x)\n",
    "        return x_h + x_w\n"
   ],
   "id": "1c286600d11dee33",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.388841Z",
     "start_time": "2025-03-17T08:00:56.372336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "separable_conv = SpatiallySeparableConv(3, 64)\n",
    "output_separable = separable_conv(input_tensor)\n",
    "print(\"SpatiallySeparableConv output shape:\", output_separable.shape)  # 預期輸出: torch.Size([1, 64, 224, 224])"
   ],
   "id": "ac4a562437d6654f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatiallySeparableConv output shape: torch.Size([1, 64, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref6\"></a>\n",
    "<h1 align=center><font size = 5>深度可分離卷積（Depthwise Separable Convolution）</h1 >"
   ],
   "id": "8a99a43e18f827d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.432394Z",
     "start_time": "2025-03-17T08:00:56.428884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n"
   ],
   "id": "eafd99e7394cf80f",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.441447Z",
     "start_time": "2025-03-17T08:00:56.435404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "depthwise_conv = DepthwiseSeparableConv(3, 64)\n",
    "output_depthwise = depthwise_conv(input_tensor)\n",
    "print(\"DepthwiseSeparableConv output shape:\", output_depthwise.shape)  # 預期輸出: torch.Size([1, 64, 224, 224])"
   ],
   "id": "4a8cf236516bbe1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthwiseSeparableConv output shape: torch.Size([1, 64, 224, 224])\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref7\"></a>\n",
    "<h1 align=center><font size = 5>展平卷積（Flattened Convolution）</h1 >"
   ],
   "id": "f7981751375bc2fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.465006Z",
     "start_time": "2025-03-17T08:00:56.461496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 修正後的 FlattenedConv 類別\n",
    "class FlattenedConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size=1)  # 修正輸入通道\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_flat = x.view(x.size(0), x.size(1), -1)  # 形狀: (batch_size, in_channels, H*W)\n",
    "        output = self.conv1d(x_flat)\n",
    "        return output"
   ],
   "id": "38ee6ef549c5460a",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.490466Z",
     "start_time": "2025-03-17T08:00:56.485547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_conv = FlattenedConv(3, 64, 3)\n",
    "input_flattened = input_tensor  # 不需手動展平，交給 forward\n",
    "output_flattened = flattened_conv(input_flattened)\n",
    "print(\"FlattenedConv output shape:\", output_flattened.shape)  # 預期輸出: torch.Size([1, 64, 224*224])"
   ],
   "id": "2566d5ca94920181",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlattenedConv output shape: torch.Size([1, 64, 50176])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref8\"></a>\n",
    "<h1 align=center><font size = 5>分組卷積（Grouped Convolution）</h1 >"
   ],
   "id": "37293334ba079691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.513107Z",
     "start_time": "2025-03-17T08:00:56.510731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GroupedConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, groups):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, groups=groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "3f31738978bb25d0",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.537921Z",
     "start_time": "2025-03-17T08:00:56.533155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_conv = GroupedConv(3, 63, 3, groups=3)\n",
    "output_grouped = grouped_conv(input_tensor)\n",
    "print(\"GroupedConv output shape:\", output_grouped.shape)  # 預期輸出: torch.Size([1, 63, 222, 222])"
   ],
   "id": "2dc7c8b223790dee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupedConv output shape: torch.Size([1, 63, 222, 222])\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<a id=\"ref9\"></a>\n",
    "<h1 align=center><font size = 5>混洗分組卷積（Shuffled Grouped Convolution）</h1 >"
   ],
   "id": "dcb2cc2548d8e3a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.561116Z",
     "start_time": "2025-03-17T08:00:56.557113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ShuffledGroupedConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, groups):\n",
    "        super().__init__()\n",
    "        assert in_channels % groups == 0 and out_channels % groups == 0\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, groups=groups)\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        channels_per_group = channels // self.groups\n",
    "        x = x.view(batch_size, self.groups, channels_per_group, height, width)\n",
    "        x = torch.transpose(x, 1, 2).contiguous()\n",
    "        x = x.view(batch_size, channels, height, width)\n",
    "        return x\n"
   ],
   "id": "2e696dd5fabe1f70",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T08:00:56.586284Z",
     "start_time": "2025-03-17T08:00:56.580204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shuffled_conv = ShuffledGroupedConv(3, 63, 3, groups=3)\n",
    "output_shuffled = shuffled_conv(input_tensor)\n",
    "print(\"ShuffledGroupedConv output shape:\", output_shuffled.shape)  # 預期輸出: torch.Size([1, 63, 222, 222])"
   ],
   "id": "67757c9364657529",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffledGroupedConv output shape: torch.Size([1, 63, 222, 222])\n"
     ]
    }
   ],
   "execution_count": 84
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
